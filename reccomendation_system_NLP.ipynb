{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b16ec0d",
   "metadata": {
    "id": "8b16ec0d"
   },
   "source": [
    "# Building a Recommendation System with Hugging Face Transformers  \n",
    "\n",
    "Learn how to build the recommendation system with advanced technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bdc09f",
   "metadata": {
    "id": "b2bdc09f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.38.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: torch in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\deepali\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wJs2YvIMvO9Q",
   "metadata": {
    "id": "wJs2YvIMvO9Q"
   },
   "source": [
    "# [Colab only] Connect to your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SHVae3MHvI9g",
   "metadata": {
    "id": "SHVae3MHvI9g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('anime.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df['description'] = df['name'] +' '+ df['genre'] + ' ' +df['type']+' episodes: '+ df['episodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86588d4b-2119-4930-b6b3-39f2165b410b",
   "metadata": {
    "id": "UJskkHs1wW6r"
   },
   "source": [
    "In the code above, we read the dataset with Pandas and dropped all the missing data. \n",
    "\n",
    "Then, we create a feature called \"description\" that contains all the information from the available data, such as \n",
    "1. name\n",
    "2. genre\n",
    "3. type\n",
    "4. episode number.\n",
    "\n",
    "The new column would become our basis for the recommendation system. It would be better to have more complete information, such as the anime plot and summary, but let’s be content with this one for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af9755",
   "metadata": {
    "id": "19af9755"
   },
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UJskkHs1wW6r",
   "metadata": {
    "id": "UJskkHs1wW6r"
   },
   "source": [
    "Next, we would use Hugging Face Transformers to load an embedding model and transform the text into a numerical vector. Specifically, we would use sentence embedding to transform the whole sentence.\n",
    "\n",
    "The recommendation system would be based on the embedding from all the anime “description” we will perform soon. \n",
    "\n",
    "We would use the cosine similarity method, which measures the similarity of two vectors. \n",
    "By measuring the similarity between the anime “description” embedding and the user's query input embedding, we can get precise items to recommend.\n",
    "\n",
    "The embedding similarity approach sounds simple, but it can be powerful compared to the classic recommendation system model, as it can capture the semantic relationship between words and provide contextual meaning for the recommendation process.\n",
    "\n",
    "We would use the embedding model sentence transformers from the Hugging Face for this tutorial. To transform the sentence into embedding, we would use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0153603",
   "metadata": {
    "id": "b0153603"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eccb1cf3b0f4c2ba5037171db87b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Deepali\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4152b035164f3881734e98d488bac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f94cc074e9943539ff607a761bf3456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c83acfecc4988978e7aeba76a18e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffe3b43b87b4a948360398b89b98b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6e41f680b40298b4b8c43c50b1dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "  encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "  with torch.no_grad():\n",
    "      model_output = model(**encoded_input)\n",
    "\n",
    "  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "  sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "  return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5eaed7",
   "metadata": {
    "id": "2f5eaed7"
   },
   "source": [
    "Try the embedding process and see the vector result with the following code. However, I would not show the output as it’s pretty long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc6b0bb",
   "metadata": {
    "id": "2fc6b0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n"
     ]
    }
   ],
   "source": [
    "sentences = ['Some great movie', 'Another funny movie']\n",
    "result = get_embeddings(sentences)\n",
    "print(\"Sentence embeddings:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c145d9-08bc-4d7f-9565-a4c2e648fb89",
   "metadata": {
    "id": "UJskkHs1wW6r"
   },
   "source": [
    "To make things easier, Hugging Face maintains a Python package for embedding sentence transformers, which would minimize the whole transformation process in 3 lines of code. Install the necessary package using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321d106",
   "metadata": {
    "id": "c321d106"
   },
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e1c3d3-d002-41b8-b5a4-7f8d3d0a6a82",
   "metadata": {
    "id": "c321d106"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbeff16892d54c7081cebd0e88d3137d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81cc5443d43411b85a37f8efed833af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25444c3dc14a4ecea5c7a1401028b347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec91ee2de14c79835c73aaf973479c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf07af73d6a84221a58b3851927466be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then, we can transform the whole anime “description” with the following code.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "anime_embeddings = model.encode(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a03ea2",
   "metadata": {
    "id": "93a03ea2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# With the embedding database is ready, we would create a function to take user input and perform cosine similarity as a recommendation system.\n",
    "\n",
    "def get_recommendations(query, embeddings, df, top_n=5):\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)\n",
    "    top_indices = similarities[0].argsort()[-top_n:][::-1]\n",
    "    return df.iloc[top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8907618-3861-4163-860a-bd50b23757e9",
   "metadata": {
    "id": "UJskkHs1wW6r"
   },
   "source": [
    "Now that everything is ready, we can try the recommendation system. Here is an example of acquiring the top five anime recommendations from the user input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81032fee",
   "metadata": {
    "id": "81032fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          name  \\\n",
      "7363  Sentou Yousei Shoujo Tasukete! Mave-chan   \n",
      "8140            Anime TV de Hakken! Tamagotchi   \n",
      "4294      SKET Dance: SD Character Flash Anime   \n",
      "1061                        Isshuukan Friends.   \n",
      "2850                       Oshiete! Galko-chan   \n",
      "\n",
      "                                             genre  \n",
      "7363  Comedy, Parody, Sci-Fi, Shounen, Super Power  \n",
      "8140          Comedy, Fantasy, Kids, Slice of Life  \n",
      "4294                       Comedy, School, Shounen  \n",
      "1061        Comedy, School, Shounen, Slice of Life  \n",
      "2850                 Comedy, School, Slice of Life  \n"
     ]
    }
   ],
   "source": [
    "query = \"Funny anime I can watch with friends\"\n",
    "recommendations = get_recommendations(query, anime_embeddings, df)\n",
    "print(recommendations[['name', 'genre']])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
